---
title: "R Notebook"
output: html_notebook
---

This is the first look at the data that includes AGE 11 A.
- Only includes the counted files, and the excluded files
- Does NOT include the revised files 

Goal: To intake the data then look at whole brain counts

Method: Will be recycling the code from the AGE 10 VAL project.



# Loading the data
```{r}

# load some libs 
library(ggplot2)
library(reshape2)
library(RColorBrewer)
library(stringr)
library(plyr)


# load the data
csvfiles = list.files(path = "All AGE 10 series counts-03232018/CombinedCounts/", full.names = TRUE)
raw = do.call("rbind", lapply(csvfiles, FUN = function(file) read.csv(file, header = TRUE, sep = ",")))

# make the column names easier to read by removing the 'X.'
colnames(raw) <- gsub('X.', '', colnames(raw), fixed = TRUE)

# Change Mouse ID to a factor, not a numeric
raw$Mouse.ID. = as.factor(raw$Mouse.ID.)

# Merge in animal details
animal_details = read.csv("animal_details.csv")
animal_details$Mouse.ID. = as.factor(animal_details$ID)
raw = merge(animal_details, raw, by = "Mouse.ID.")

# Convert time (hh:mm) to minutes 
raw$DELTA.T = sapply(strsplit(as.character(raw$DELTA.T), ":"), function(x)
{
  x = as.numeric(x)
  x[1] * 60 + x[2]
}
)



# show the number of different values per ROI variables
factor(levels(raw$System.)) # 17
factor(levels(raw$Major.ROI.)) # 69
factor(levels(raw$Sub.ROI)) # 82

# Useful plotting shortcuts
rx = theme(axis.text.x = element_text(angle = 90, hjust = 1))

nrow(raw)

```

# Exclude the data

```{r}


# KK's usual file naming pattern is:
# seq _ z _ bregma _ animal _ flags .tif
# So find num_num_num_num_ with optional '-' for negative bregma
root_pat = "^[:digit:]{1,3}_[:digit:]{1,3}_[-]?.{1,3}_[:xdigit:]{1,4}_"

# Load in the image metadata and clean it


exfiles = list.files(path = "All AGE 10 series counts-03232018/Rotations or Exclusions - From Manual Validations", full.names = TRUE)
ex = do.call("rbind", lapply(exfiles, FUN = function(file) read.csv(file, header = TRUE, sep = ",")))


# Clean the 'ex' dataframe
clean_shellshit = function(string, pattern)
{
    new = str_extract(string, pattern)
    string = new
}
pat_shell = "[:digit:]{1,4}"
ex$Width = mapply(clean_shellshit, string = ex$Width, pattern = pat_shell)
ex$Height = mapply(clean_shellshit, string = ex$Height, pattern = pat_shell) 
ex$Width = as.numeric(ex$Width)
ex$Height = as.numeric(ex$Height)

# Flag the excluded files in the RAW dataframe
# 1) Work on each filename in the RAW
# 2) Compare root names with exclusion list
# 3) If same, then label every observation under that file to be excluded
for (filename in levels(factor(raw$File.Name.)))
{
    a1 = str_extract(filename, root_pat)
    a2 = str_extract(ex$Name[ex$Width < ex$Height], root_pat) # list of portrait images (bad)
    if (any(a1 %in% a2)) # if it's a bad image
    {
        raw$is_excluded[raw$File.Name. == filename] = TRUE # then flag exclude TRUE
    } else raw$is_excluded[raw$File.Name. == filename] = FALSE
}

# Find the percent excluded
count(raw$is_excluded)

# Save a new dataframe of after exclusions
rawe = raw[raw$is_excluded==TRUE,]
write.csv(rawe, file="RAW_AFTER_EXCLUSIONS.csv")

# raw is now after exclusions
oldraw = raw
raw = rawe



```

# Look at whole brain data

```{r}

# This defines the channel sets

# define all the sets of channels as a list of variables
# 5 groups total: mean, lowSD, midSD, hiSD, and total
channels_mean = list(
    dapimean = raw$Ch1.Mean.,
    gfpmean = raw$Ch2.Mean.,
    gfapmean = raw$Ch3.Mean.,
    arcmean = raw$Ch4.Mean.)
channels_lowSD = list(
    dapilow = raw$Ch1..m.0.5sd.,
    gfplow = raw$Ch2..m.0.5sd.,
    gfaplow = raw$Ch3..m.0.5sd.,
    arclow = raw$Ch4..m.0.5sd.,
    ollow = raw$OL..m.0.5sd.)
channels_midSD = list(
    dapimid = raw$Ch1..m.0.5sd...m.0.5sd..,
    gfpmid = raw$Ch2..m.0.5sd...m.0.5sd..,
    gfapmid = raw$Ch3..m.0.5sd...m.0.5sd..,
    arcmid = raw$Ch4..m.0.5sd...m.0.5sd..,
    olmid = raw$OL..m.0.5sd...m.0.5sd..)
channels_hiSD = list(
    dapihi = raw$Ch1..m.0.5sd..1,
    gfphi = raw$Ch2..m.0.5sd..1,
    gfaphi = raw$Ch3..m.0.5sd..1,
    archi = raw$Ch4..m.0.5sd..1,
    olhi = raw$OL..m.0.5sd..1)
channels_total = list(
    dapitot = raw$Ch1.Total.,
    gfptot = raw$Ch2.Total.,
    gfaptot = raw$Ch3.Total.,
    arctot = raw$Ch4.Total.,
    oltot = raw$OL.Total.)



# Which areas in each animals have the most counts? 


# define function to get heatmap
# accepts channel list as argument, then x axis, then y axis factors
heat_set = function(ch, x1, y1) {
    names = names(ch) # get all names to a list
    j = 1 # init
    for (counts in ch) {
        title = names[j]
        j = j + 1
        print(
            ggplot(
                raw, aes(y = y1, x = x1)) + geom_tile(aes(fill = counts)) +
                labs(title = title) +rx
            )
    }
}

heat_set(channels_mean, raw$Mouse.ID., raw$System.)
heat_set(channels_hiSD, raw$Mouse.ID., raw$System.)
heat_set(channels_lowSD, raw$Mouse.ID., raw$System.)
heat_set(channels_midSD, raw$Mouse.ID., raw$System.)
heat_set(channels_total, raw$Mouse.ID., raw$System.)

# Determine whether each hemisphere is represented

```

# Try to do a whole brain analysis

```{r}
ggplot(raw, aes(GROUP, Ch4.Mean.)) + geom_jitter()


ggplot(raw, aes(GROUP, OL.Total.)) + geom_col()
ggplot(raw, aes(GROUP, Ch1.Mean.)) + geom_col()

```


